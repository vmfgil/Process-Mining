import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import matplotlib.dates as mdates
import seaborn as sns
import networkx as nx
from collections import Counter
import io
import base64

# Imports de Process Mining (PM4PY)
import pm4py
from pm4py.objects.conversion.log import converter as log_converter
from pm4py.objects.conversion.process_tree import converter as pt_converter
from pm4py.visualization.petri_net import visualizer as pn_visualizer
from pm4py.visualization.dfg import visualizer as dfg_visualizer
from pm4py.algo.discovery.dfg import algorithm as dfg_discovery
from pm4py.algo.discovery.inductive import algorithm as inductive_miner
from pm4py.algo.discovery.heuristics import algorithm as heuristics_miner
from pm4py.algo.evaluation.replay_fitness import algorithm as replay_fitness_evaluator
from pm4py.algo.evaluation.precision import algorithm as precision_evaluator
from pm4py.algo.evaluation.generalization import algorithm as generalization_evaluator
from pm4py.algo.evaluation.simplicity import algorithm as simplicity_evaluator
from pm4py.algo.filtering.log.variants import variants_filter
from pm4py.algo.conformance.alignments.petri_net import algorithm as alignments_miner

# --- 1. CONFIGURA√á√ÉO DA P√ÅGINA E ESTILO ---
st.set_page_config(
    page_title="Transforma√ß√£o Inteligente de Processos",
    page_icon="‚ú®",
    layout="wide"
)

# --- ESTILO CSS ---
# --- ESTILO CSS ---
st.markdown("""
<style>
    @import url('https://fonts.googleapis.com/css2?family=Poppins:wght@400;600;700&display=swap');
    html, body, [class*="st-"] { font-family: 'Poppins', sans-serif; }
    :root {
        --primary-color: #EF4444; 
        --secondary-color: #3B82F6;
        --baby-blue-bg: #A0E9FF;
        --background-color: #0F172A;
        --sidebar-background: #1E293B;
        --inactive-button-bg: rgba(51, 65, 85, 0.5);
        --text-color-dark-bg: #FFFFFF;
        --text-color-light-bg: #0F172A;
        --border-color: #334155;
        --card-background-color: #FFFFFF;
        --card-text-color: #0F172A;
        --card-border-color: #E2E8F0;
    }
    .stApp { background-color: var(--background-color); color: var(--text-color-dark-bg); }
    h1, h2, h3 { color: var(--text-color-dark-bg); font-weight: 600; }
    
    [data-testid="stSidebar"] h3 { color: var(--text-color-dark-bg) !important; }

    /* --- ESTILOS PARA BOT√ïES DE NAVEGA√á√ÉO --- */
    div[data-testid="stHorizontalBlock"] .stButton>button {
        border: 1px solid var(--border-color) !important;
        background-color: var(--inactive-button-bg) !important;
        color: var(--text-color-dark-bg) !important;
        font-weight: 600;
        transition: all 0.2s ease-in-out;
    }
    div[data-testid="stHorizontalBlock"] .stButton>button:hover {
        border-color: var(--primary-color) !important;
        background-color: rgba(239, 68, 68, 0.2) !important;
    }
    div.active-button .stButton>button {
        background-color: var(--primary-color) !important;
        color: var(--text-color-dark-bg) !important;
        border: 1px solid var(--primary-color) !important;
        font-weight: 700 !important;
    }

    /* Painel Lateral */
    [data-testid="stSidebar"] { background-color: var(--sidebar-background); border-right: 1px solid var(--border-color); }
    [data-testid="stSidebar"] .stButton>button {
        background-color: var(--card-background-color) !important;
        color: var(--card-text-color) !important;
    }
    
    /* --- CART√ïES --- */
    .card {
        background-color: var(--card-background-color);
        color: var(--card-text-color);
        border-radius: 12px;
        padding: 20px 25px;
        border: 1px solid var(--card-border-color);
        height: 100%;
        display: flex;
        flex-direction: column;
        margin-bottom: 25px;
    }
    .card-header { padding-bottom: 10px; border-bottom: 1px solid var(--card-border-color); }
    .card .card-header h4 { color: var(--card-text-color); font-size: 1.1rem; margin: 0; display: flex; align-items: center; gap: 8px; }
    .card-body { flex-grow: 1; padding-top: 15px; }
    .dataframe-card-body [data-testid="stDataFrame"] { border: none !important; }
    
    /* --- BOT√ïES DE UPLOAD --- */
    section[data-testid="stFileUploader"] button,
    div[data-baseweb="file-uploader"] button {
        background-color: var(--baby-blue-bg) !important;
        color: var(--text-color-light-bg) !important;
        border: none !important;
        font-weight: 600 !important;
    }
    
    /* --- BOT√ÉO DE AN√ÅLISE --- */
    .iniciar-analise-button .stButton>button {
        background-color: var(--baby-blue-bg) !important;
        color: var(--text-color-light-bg) !important;
        border: 2px solid var(--baby-blue-bg) !important;
        font-weight: 700 !important;
    }
    
    /* --- BOT√ÉO DE LOGIN --- */
    .login-button .stButton>button {
        background-color: var(--baby-blue-bg) !important;
        color: var(--text-color-light-bg) !important;
        border: 2px solid var(--baby-blue-bg) !important;
        font-weight: 700 !important;
    }
    
    /* --- CART√ïES DE M√âTRICAS (KPIs) --- */
    [data-testid="stMetric"] {
        background-color: var(--card-background-color);
        border: 1px solid var(--card-border-color);
        border-radius: 12px;
        padding: 20px;
    }
    [data-testid="stMetric"] label, [data-testid="stMetric"] [data-testid="stMetricValue"] {
        color: var(--card-text-color) !important;
    }
    
    /* Alertas */
    [data-testid="stAlert"] {
        background-color: #1E293B !important;
        border: 1px solid var(--secondary-color) !important;
        border-radius: 8px !important;
    }
    [data-testid="stAlert"] * { color: #BFDBFE !important; }
</style>
""", unsafe_allow_html=True)

# --- FUN√á√ïES AUXILIARES ---
def convert_fig_to_bytes(fig, format='png'):
    buf = io.BytesIO()
    # Definir cores para gr√°ficos, garantindo legibilidade em fundo claro (para o PNG/JPEG)
    fig.patch.set_facecolor('#FFFFFF')
    for ax in fig.get_axes():
        ax.tick_params(colors='black', which='both')
        ax.xaxis.label.set_color('black')
        ax.yaxis.label.set_color('black')
        ax.title.set_color('black')
        if ax.get_legend() is not None:
            plt.setp(ax.get_legend().get_texts(), color='black')
    fig.savefig(buf, format=format, bbox_inches='tight', dpi=150)
    buf.seek(0)
    plt.close(fig)
    return buf

def convert_gviz_to_bytes(gviz, format='png'):
    return io.BytesIO(gviz.pipe(format=format))

# Fun√ß√£o create_card ajustada para renderizar st.dataframe DENTRO da div (Problema 2)
def create_card(title, icon, chart_bytes=None, dataframe=None):
    if chart_bytes:
        b64_image = base64.b64encode(chart_bytes.getvalue()).decode()
        st.markdown(f"""
        <div class="card">
            <div class="card-header"><h4>{icon} {title}</h4></div>
            <div class="card-body">
                <img src="data:image/png;base64,{b64_image}" style="width: 100%; height: auto;">
            </div>
        </div>
        """, unsafe_allow_html=True)
    elif dataframe is not None:
        # Abre a estrutura do cart√£o
        st.markdown(f"""
        <div class="card">
            <div class="card-header"><h4>{icon} {title}</h4></div>
            <div class="card-body dataframe-card-body">
        """, unsafe_allow_html=True)
        # Usa st.dataframe para renderizar a tabela DENTRO do corpo do cart√£o
        st.dataframe(dataframe, use_container_width=True)
        # Fecha a estrutura do cart√£o
        st.markdown("</div></div>", unsafe_allow_html=True)


# --- INICIALIZA√á√ÉO DO ESTADO DA SESS√ÉO ---
if 'authenticated' not in st.session_state: st.session_state.authenticated = False
if 'current_page' not in st.session_state: st.session_state.current_page = "Dashboard"
if 'current_dashboard' not in st.session_state: st.session_state.current_dashboard = "Pr√©-Minera√ß√£o"
if 'current_section' not in st.session_state: st.session_state.current_section = "overview"
if 'dfs' not in st.session_state:
    st.session_state.dfs = {'projects': None, 'tasks': None, 'resources': None, 'resource_allocations': None, 'dependencies': None}
if 'analysis_run' not in st.session_state: st.session_state.analysis_run = False
if 'plots_pre_mining' not in st.session_state: st.session_state.plots_pre_mining = {}
if 'plots_post_mining' not in st.session_state: st.session_state.plots_post_mining = {}
if 'tables_pre_mining' not in st.session_state: st.session_state.tables_pre_mining = {}
if 'metrics' not in st.session_state: st.session_state.metrics = {}


# --- FUN√á√ïES DE AN√ÅLISE (DO SCRIPT ORIGINAL) ---
@st.cache_data
def run_pre_mining_analysis(dfs):
    plots = {}
    tables = {}
    df_projects = dfs['projects'].copy()
    df_tasks = dfs['tasks'].copy()
    df_resources = dfs['resources'].copy()
    df_resource_allocations = dfs['resource_allocations'].copy()
    df_dependencies = dfs['dependencies'].copy()

    for df in [df_projects, df_tasks, df_resource_allocations]:
        for col in ['start_date', 'end_date', 'planned_end_date', 'allocation_date']:
            if col in df.columns: df[col] = pd.to_datetime(df[col], errors='coerce')

    for col in ['project_id', 'task_id', 'resource_id']:
        for df in [df_projects, df_tasks, df_resources, df_resource_allocations, df_dependencies]:
            if col in df.columns: df[col] = df[col].astype(str)

    df_projects['days_diff'] = (df_projects['end_date'] - df_projects['planned_end_date']).dt.days
    df_projects['actual_duration_days'] = (df_projects['end_date'] - df_projects['start_date']).dt.days
    df_projects['project_type'] = df_projects['project_name'].str.extract(r'Projeto \d+: (.*?) ')
    df_projects['completion_month'] = df_projects['end_date'].dt.to_period('M').astype(str)

    df_alloc_costs = df_resource_allocations.merge(df_resources, on='resource_id')
    df_alloc_costs['cost_of_work'] = df_alloc_costs['hours_worked'] * df_alloc_costs['cost_per_hour']
    
    project_aggregates = df_alloc_costs.groupby('project_id').agg(total_actual_cost=('cost_of_work', 'sum'), num_resources=('resource_id', 'nunique')).reset_index()
    df_projects = df_projects.merge(project_aggregates, on='project_id', how='left')
    df_projects['cost_diff'] = df_projects['total_actual_cost'] - df_projects['budget_impact']
    df_projects['cost_per_day'] = df_projects['total_actual_cost'] / df_projects['actual_duration_days'].replace(0, np.nan)
    
    df_full_context = df_tasks.merge(df_projects, on='project_id', suffixes=('_task', '_project'))
    df_full_context = df_full_context.merge(df_resource_allocations.drop(columns=['project_id'], errors='ignore'), on='task_id')
    df_full_context = df_full_context.merge(df_resources, on='resource_id')
    df_full_context['cost_of_work'] = df_full_context['hours_worked'] * df_full_context['cost_per_hour']

    log_df_final = df_full_context[['project_id', 'task_name', 'allocation_date', 'resource_name']].copy()
    log_df_final.rename(columns={'project_id': 'case:concept:name', 'task_name': 'concept:name', 'allocation_date': 'time:timestamp', 'resource_name': 'org:resource'}, inplace=True)
    log_df_final['lifecycle:transition'] = 'complete'
    event_log_pm4py = pm4py.convert_to_event_log(log_df_final)
    
    tables['kpi_data'] = {
        'Total de Projetos': len(df_projects),
        'Total de Tarefas': len(df_tasks),
        'Total de Recursos': len(df_resources),
        'Dura√ß√£o M√©dia (dias)': f"{df_projects['actual_duration_days'].mean():.1f}"
    }
    tables['outlier_duration'] = df_projects.sort_values('actual_duration_days', ascending=False).head(5)
    tables['outlier_cost'] = df_projects.sort_values('total_actual_cost', ascending=False).head(5)
    fig, ax = plt.subplots(figsize=(8, 5)); sns.scatterplot(data=df_projects, x='days_diff', y='cost_diff', hue='project_type', s=80, alpha=0.7, ax=ax); ax.axhline(0, color='black', ls='--'); ax.axvline(0, color='black', ls='--'); ax.set_title("Matriz de Performance")
    plots['performance_matrix'] = convert_fig_to_bytes(fig)
    fig, ax = plt.subplots(figsize=(8, 4)); sns.boxplot(x=df_projects['actual_duration_days'], ax=ax, color="skyblue"); sns.stripplot(x=df_projects['actual_duration_days'], color="blue", size=4, jitter=True, alpha=0.5, ax=ax); ax.set_title("Distribui√ß√£o da Dura√ß√£o dos Projetos")
    plots['case_durations_boxplot'] = convert_fig_to_bytes(fig)
    
    lead_times = log_df_final.groupby("case:concept:name")["time:timestamp"].agg(["min", "max"]).reset_index()
    lead_times["lead_time_days"] = (lead_times["max"] - lead_times["min"]).dt.total_seconds() / (24*60*60)
    def compute_avg_throughput(group):
        group = group.sort_values("time:timestamp"); deltas = group["time:timestamp"].diff().dropna()
        return deltas.mean().total_seconds() if not deltas.empty else 0
    throughput_per_case = log_df_final.groupby("case:concept:name").apply(compute_avg_throughput).reset_index(name="avg_throughput_seconds")
    throughput_per_case["avg_throughput_hours"] = throughput_per_case["avg_throughput_seconds"] / 3600
    perf_df = pd.merge(lead_times, throughput_per_case, on="case:concept:name")
    tables['perf_stats'] = perf_df[["lead_time_days", "avg_throughput_hours"]].describe()
    fig, ax = plt.subplots(figsize=(8, 4)); sns.histplot(perf_df["lead_time_days"], bins=20, kde=True, ax=ax); ax.set_title("Distribui√ß√£o do Lead Time (dias)")
    plots['lead_time_hist'] = convert_fig_to_bytes(fig)
    fig, ax = plt.subplots(figsize=(8, 4)); sns.histplot(perf_df["avg_throughput_hours"], bins=20, kde=True, color='green', ax=ax); ax.set_title("Distribui√ß√£o do Throughput (horas)")
    plots['throughput_hist'] = convert_fig_to_bytes(fig)
    fig, ax = plt.subplots(figsize=(8, 4)); sns.boxplot(x=perf_df["avg_throughput_hours"], color='lightgreen', ax=ax); ax.set_title("Boxplot do Throughput (horas)")
    plots['throughput_boxplot'] = convert_fig_to_bytes(fig)
    fig, ax = plt.subplots(figsize=(8, 5)); sns.regplot(x="avg_throughput_hours", y="lead_time_days", data=perf_df, ax=ax); ax.set_title("Rela√ß√£o Lead Time vs Throughput")
    plots['lead_time_vs_throughput'] = convert_fig_to_bytes(fig)
    
    service_times = df_full_context.groupby('task_name')['hours_worked'].mean().reset_index()
    service_times['service_time_days'] = service_times['hours_worked'] / 8
    fig, ax = plt.subplots(figsize=(8, 5)); sns.barplot(x='service_time_days', y='task_name', data=service_times.sort_values('service_time_days', ascending=False).head(10), ax=ax, hue='task_name', legend=False, palette='viridis'); ax.set_title("Tempo M√©dio de Execu√ß√£o por Atividade")
    plots['activity_service_times'] = convert_fig_to_bytes(fig)
    df_handoff = log_df_final.sort_values(['case:concept:name', 'time:timestamp'])
    df_handoff['previous_activity_end_time'] = df_handoff.groupby('case:concept:name')['time:timestamp'].shift(1)
    df_handoff['handoff_time_days'] = (df_handoff['time:timestamp'] - df_handoff['previous_activity_end_time']).dt.total_seconds() / (24*3600)
    df_handoff['previous_activity'] = df_handoff.groupby('case:concept:name')['concept:name'].shift(1)
    handoff_stats = df_handoff.groupby(['previous_activity', 'concept:name'])['handoff_time_days'].mean().reset_index().sort_values('handoff_time_days', ascending=False)
    handoff_stats['transition'] = handoff_stats['previous_activity'].fillna('') + ' -> ' + handoff_stats['concept:name'].fillna('')
    fig, ax = plt.subplots(figsize=(8, 5)); sns.barplot(data=handoff_stats.head(10), y='transition', x='handoff_time_days', ax=ax, hue='transition', legend=False, palette='magma'); ax.set_title("Top 10 Handoffs por Tempo de Espera")
    plots['top_handoffs'] = convert_fig_to_bytes(fig)
    handoff_stats['estimated_cost_of_wait'] = handoff_stats['handoff_time_days'] * df_projects['cost_per_day'].mean()
    fig, ax = plt.subplots(figsize=(8, 5)); sns.barplot(data=handoff_stats.sort_values('estimated_cost_of_wait', ascending=False).head(10), y='transition', x='estimated_cost_of_wait', ax=ax, hue='transition', legend=False, palette='Reds_r'); ax.set_title("Top 10 Handoffs por Custo de Espera")
    plots['top_handoffs_cost'] = convert_fig_to_bytes(fig)

    activity_counts = df_tasks["task_name"].value_counts()
    fig, ax = plt.subplots(figsize=(8, 5)); sns.barplot(x=activity_counts.head(10).values, y=activity_counts.head(10).index, ax=ax); ax.set_title("Atividades Mais Frequentes")
    plots['top_activities_plot'] = convert_fig_to_bytes(fig)
    resource_workload = df_full_context.groupby('resource_name')['hours_worked'].sum().sort_values(ascending=False).reset_index()
    fig, ax = plt.subplots(figsize=(8, 5)); sns.barplot(x='hours_worked', y='resource_name', data=resource_workload.head(10), ax=ax, hue='resource_name', legend=False, palette='plasma'); ax.set_title("Top 10 Recursos por Horas Trabalhadas")
    plots['resource_workload'] = convert_fig_to_bytes(fig)
    resource_metrics = df_full_context.groupby("resource_name").agg(unique_cases=('project_id', 'nunique'), event_count=('task_id', 'count')).reset_index()
    resource_metrics["avg_events_per_case"] = resource_metrics["event_count"] / resource_metrics["unique_cases"]
    fig, ax = plt.subplots(figsize=(8, 5)); sns.barplot(x='avg_events_per_case', y='resource_name', data=resource_metrics.sort_values('avg_events_per_case', ascending=False).head(10), ax=ax, hue='resource_name', legend=False, palette='coolwarm'); ax.set_title("Recursos por M√©dia de Tarefas por Projeto")
    plots['resource_avg_events'] = convert_fig_to_bytes(fig)
    resource_activity_matrix_pivot = df_full_context.pivot_table(index='resource_name', columns='task_name', values='hours_worked', aggfunc='sum').fillna(0)
    fig, ax = plt.subplots(figsize=(12, 8)); sns.heatmap(resource_activity_matrix_pivot, cmap='YlGnBu', annot=True, fmt=".0f", ax=ax, annot_kws={"size": 8}); ax.set_title("Heatmap de Esfor√ßo por Recurso e Atividade")
    plots['resource_activity_matrix'] = convert_fig_to_bytes(fig)
    handoff_counts = Counter((trace[i]['org:resource'], trace[i+1]['org:resource']) for trace in event_log_pm4py for i in range(len(trace) - 1) if 'org:resource' in trace[i] and 'org:resource' in trace[i+1] and trace[i]['org:resource'] != trace[i+1]['org:resource'])
    df_resource_handoffs = pd.DataFrame(handoff_counts.most_common(10), columns=['Handoff', 'Contagem'])
    df_resource_handoffs['Handoff'] = df_resource_handoffs['Handoff'].apply(lambda x: f"{x[0]} -> {x[1]}")
    fig, ax = plt.subplots(figsize=(8, 5)); sns.barplot(x='Contagem', y='Handoff', data=df_resource_handoffs, ax=ax, hue='Handoff', legend=False, palette='rocket'); ax.set_title("Top 10 Handoffs entre Recursos")
    plots['resource_handoffs'] = convert_fig_to_bytes(fig)
    cost_by_resource_type = df_full_context.groupby('resource_type')['cost_of_work'].sum().sort_values(ascending=False).reset_index()
    fig, ax = plt.subplots(figsize=(8, 4)); sns.barplot(data=cost_by_resource_type, x='cost_of_work', y='resource_type', ax=ax, hue='resource_type', legend=False, palette='magma'); ax.set_title("Custo por Tipo de Recurso")
    plots['cost_by_resource_type'] = convert_fig_to_bytes(fig)
    
    variants_df = log_df_final.groupby('case:concept:name')['concept:name'].apply(list).reset_index(name='trace')
    variants_df['variant_str'] = variants_df['trace'].apply(lambda x: ' -> '.join(x))
    variant_analysis = variants_df['variant_str'].value_counts().reset_index(name='frequency')
    variant_analysis['percentage'] = (variant_analysis['frequency'] / variant_analysis['frequency'].sum()) * 100
    tables['variants_table'] = variant_analysis.head(10)
    fig, ax = plt.subplots(figsize=(12, 6)); sns.barplot(x='frequency', y='variant_str', data=variant_analysis.head(10), ax=ax, orient='h', hue='variant_str', legend=False, palette='coolwarm'); ax.set_title("Top 10 Variantes de Processo por Frequ√™ncia")
    plots['variants_frequency'] = convert_fig_to_bytes(fig)
    rework_loops = Counter(f"{trace[i]} -> {trace[i+1]} -> {trace[i]}" for trace in variants_df['trace'] for i in range(len(trace) - 2) if trace[i] == trace[i+2] and trace[i] != trace[i+1])
    tables['rework_loops_table'] = pd.DataFrame(rework_loops.most_common(10), columns=['rework_loop', 'frequency'])
    
    delayed_projects = df_projects[df_projects['days_diff'] > 0]
    tables['cost_of_delay_kpis'] = {
        'Custo Total Projetos Atrasados': f"‚Ç¨{delayed_projects['total_actual_cost'].sum():,.2f}",
        'Atraso M√©dio (dias)': f"{delayed_projects['days_diff'].mean():.1f}",
        'Custo M√©dio/Dia Atraso': f"‚Ç¨{(delayed_projects.get('total_actual_cost', 0) / delayed_projects['days_diff']).mean():,.2f}"
    }
    min_res, max_res = df_projects['num_resources'].min(), df_projects['num_resources'].max()
    bins = np.linspace(min_res, max_res, 5, dtype=int) if max_res > min_res else [min_res, max_res]
    df_projects['team_size_bin_dynamic'] = pd.cut(df_projects['num_resources'], bins=bins, include_lowest=True, duplicates='drop').astype(str)
    fig, ax = plt.subplots(figsize=(8, 5)); sns.boxplot(data=df_projects.dropna(subset=['team_size_bin_dynamic']), x='team_size_bin_dynamic', y='days_diff', ax=ax, hue='team_size_bin_dynamic', legend=False, palette='flare'); ax.set_title("Impacto do Tamanho da Equipa no Atraso")
    plots['delay_by_teamsize'] = convert_fig_to_bytes(fig)
    median_duration_by_team_size = df_projects.groupby('team_size_bin_dynamic')['actual_duration_days'].median().reset_index()
    fig, ax = plt.subplots(figsize=(8, 5)); sns.barplot(data=median_duration_by_team_size, x='team_size_bin_dynamic', y='actual_duration_days', ax=ax, hue='team_size_bin_dynamic', legend=False, palette='crest'); ax.set_title("Dura√ß√£o Mediana por Tamanho da Equipa")
    plots['median_duration_by_teamsize'] = convert_fig_to_bytes(fig)
    df_alloc_costs['day_of_week'] = df_alloc_costs['allocation_date'].dt.day_name()
    weekday_order = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']
    fig, ax = plt.subplots(figsize=(8, 5)); sns.barplot(data=df_alloc_costs.groupby('day_of_week')['hours_worked'].sum().reindex(weekday_order).reset_index(), x='day_of_week', y='hours_worked', ax=ax, hue='day_of_week', legend=False, palette='plasma'); ax.set_title("Efici√™ncia Semanal (Horas Trabalhadas)"); plt.xticks(rotation=45)
    plots['weekly_efficiency'] = convert_fig_to_bytes(fig)
    df_tasks_analysis = df_tasks.copy(); df_tasks_analysis['service_time_days'] = (df_tasks['end_date'] - df_tasks['start_date']).dt.total_seconds() / (24*60*60)
    df_tasks_analysis.sort_values(['project_id', 'start_date'], inplace=True); df_tasks_analysis['previous_task_end'] = df_tasks_analysis.groupby('project_id')['end_date'].shift(1)
    df_tasks_analysis['waiting_time_days'] = (df_tasks_analysis['start_date'] - df_tasks_analysis['previous_task_end']).dt.total_seconds() / (24*60*60)
    df_tasks_analysis['waiting_time_days'] = df_tasks_analysis['waiting_time_days'].apply(lambda x: x if x > 0 else 0)
    df_tasks_with_resources = df_tasks_analysis.merge(df_full_context[['task_id', 'resource_name']], on='task_id', how='left').drop_duplicates()
    bottleneck_by_resource = df_tasks_with_resources.groupby('resource_name')['waiting_time_days'].mean().sort_values(ascending=False).head(15).reset_index()
    fig, ax = plt.subplots(figsize=(8, 5)); sns.barplot(data=bottleneck_by_resource, y='resource_name', x='waiting_time_days', ax=ax, hue='resource_name', legend=False, palette='rocket'); ax.set_title("Top 15 Recursos por Tempo M√©dio de Espera")
    plots['bottleneck_by_resource'] = convert_fig_to_bytes(fig)
    bottleneck_by_activity = df_tasks_analysis.groupby('task_type')[['service_time_days', 'waiting_time_days']].mean()
    fig, ax = plt.subplots(figsize=(8, 5)); bottleneck_by_activity.plot(kind='bar', stacked=True, color=['royalblue', 'crimson'], ax=ax); ax.set_title("Gargalos: Tempo de Servi√ßo vs. Espera")
    plots['service_vs_wait_stacked'] = convert_fig_to_bytes(fig)
    fig, ax = plt.subplots(figsize=(8, 5)); sns.regplot(data=bottleneck_by_activity.reset_index(), x='service_time_days', y='waiting_time_days', ax=ax); ax.set_title("Tempo de Espera vs. Tempo de Execu√ß√£o")
    plots['wait_vs_service_scatter'] = convert_fig_to_bytes(fig)
    df_wait_over_time = df_tasks_analysis.merge(df_projects[['project_id', 'completion_month']], on='project_id')
    monthly_wait_time = df_wait_over_time.groupby('completion_month')['waiting_time_days'].mean().reset_index()
    fig, ax = plt.subplots(figsize=(8, 4)); sns.lineplot(data=monthly_wait_time, x='completion_month', y='waiting_time_days', marker='o', ax=ax); plt.xticks(rotation=45); ax.set_title("Evolu√ß√£o do Tempo M√©dio de Espera")
    plots['wait_time_evolution'] = convert_fig_to_bytes(fig)
    df_perf_full = perf_df.merge(df_projects, left_on='case:concept:name', right_on='project_id')
    fig, ax = plt.subplots(figsize=(8, 5)); sns.boxplot(data=df_perf_full, x='team_size_bin_dynamic', y='avg_throughput_hours', ax=ax, hue='team_size_bin_dynamic', legend=False, palette='plasma'); ax.set_title("Benchmark de Throughput por Tamanho da Equipa")
    plots['throughput_benchmark_by_teamsize'] = convert_fig_to_bytes(fig)
    def get_phase(task_type):
        if task_type in ['Desenvolvimento', 'Corre√ß√£o', 'Revis√£o', 'Design']: return 'Desenvolvimento & Design'
        if task_type == 'Teste': return 'Teste (QA)'
        if task_type in ['Deploy', 'DBA']: return 'Opera√ß√µes & Deploy'
        return 'Outros'
    df_tasks['phase'] = df_tasks['task_type'].apply(get_phase)
    phase_times = df_tasks.groupby(['project_id', 'phase']).agg(start=('start_date', 'min'), end=('end_date', 'max')).reset_index()
    phase_times['cycle_time_days'] = (phase_times['end'] - phase_times['start']).dt.days
    avg_cycle_time_by_phase = phase_times.groupby('phase')['cycle_time_days'].mean()
    fig, ax = plt.subplots(figsize=(8, 4)); avg_cycle_time_by_phase.plot(kind='bar', color=sns.color_palette('muted'), ax=ax); ax.set_title("Dura√ß√£o M√©dia por Fase do Processo"); plt.xticks(rotation=0)
    plots['cycle_time_breakdown'] = convert_fig_to_bytes(fig)
    
    return plots, tables, event_log_pm4py, df_projects, df_tasks, df_resources, df_full_context

@st.cache_data
def run_post_mining_analysis(_event_log_pm4py, _df_projects, _df_tasks_raw, _df_resources, _df_full_context):
    plots = {}
    metrics = {}
    
    df_start_events = _df_tasks_raw[['project_id', 'task_id', 'task_name', 'start_date']].rename(columns={'start_date': 'time:timestamp', 'task_name': 'concept:name', 'project_id': 'case:concept:name'})
    df_start_events['lifecycle:transition'] = 'start'
    df_complete_events = _df_tasks_raw[['project_id', 'task_id', 'task_name', 'end_date']].rename(columns={'end_date': 'time:timestamp', 'task_name': 'concept:name', 'project_id': 'case:concept:name'})
    df_complete_events['lifecycle:transition'] = 'complete'
    log_df_full_lifecycle = pd.concat([df_start_events, df_complete_events]).sort_values('time:timestamp')
    log_full_pm4py = pm4py.convert_to_event_log(log_df_full_lifecycle)

    variants_dict = variants_filter.get_variants(_event_log_pm4py)
    top_variants_list = sorted(variants_dict.items(), key=lambda x: len(x[1]), reverse=True)[:3]
    top_variant_names = [v[0] for v in top_variants_list]
    log_top_3_variants = variants_filter.apply(_event_log_pm4py, top_variant_names)
    
    pt_inductive = inductive_miner.apply(log_top_3_variants)
    net_im, im_im, fm_im = pt_converter.apply(pt_inductive)
    gviz_im = pn_visualizer.apply(net_im, im_im, fm_im)
    plots['model_inductive_petrinet'] = convert_gviz_to_bytes(gviz_im)
    
    def plot_metrics_chart(metrics_dict, title):
        df_metrics = pd.DataFrame(list(metrics_dict.items()), columns=['M√©trica', 'Valor'])
        fig, ax = plt.subplots(figsize=(8, 4)); barplot = sns.barplot(data=df_metrics, x='M√©trica', y='Valor', ax=ax, hue='M√©trica', legend=False, palette='viridis')
        for p in barplot.patches: ax.annotate(f'{p.get_height():.2f}', (p.get_x() + p.get_width() / 2., p.get_height()), ha='center', va='center', xytext=(0, 9), textcoords='offset points')
        ax.set_title(title); ax.set_ylim(0, 1.05); return fig
        
    metrics_im = {"Fitness": replay_fitness_evaluator.apply(log_top_3_variants, net_im, im_im, fm_im, variant=replay_fitness_evaluator.Variants.TOKEN_BASED).get('average_trace_fitness', 0), "Precis√£o": precision_evaluator.apply(log_top_3_variants, net_im, im_im, fm_im), "Generaliza√ß√£o": generalization_evaluator.apply(log_top_3_variants, net_im, im_im, fm_im), "Simplicidade": simplicity_evaluator.apply(net_im)}
    plots['metrics_inductive'] = convert_fig_to_bytes(plot_metrics_chart(metrics_im, 'M√©tricas de Qualidade (Inductive Miner)'))
    metrics['inductive_miner'] = metrics_im

    net_hm, im_hm, fm_hm = heuristics_miner.apply(log_top_3_variants, parameters={heuristics_miner.Variants.CLASSIC.value.Parameters.DEPENDENCY_THRESH: 0.5})
    gviz_hm = pn_visualizer.apply(net_hm, im_hm, fm_hm)
    plots['model_heuristic_petrinet'] = convert_gviz_to_bytes(gviz_hm)
    
    metrics_hm = {"Fitness": replay_fitness_evaluator.apply(log_top_3_variants, net_hm, im_hm, fm_hm, variant=replay_fitness_evaluator.Variants.TOKEN_BASED).get('average_trace_fitness', 0), "Precis√£o": precision_evaluator.apply(log_top_3_variants, net_hm, im_hm, fm_hm), "Generaliza√ß√£o": generalization_evaluator.apply(log_top_3_variants, net_hm, im_hm, fm_hm), "Simplicidade": simplicity_evaluator.apply(net_hm)}
    plots['metrics_heuristic'] = convert_fig_to_bytes(plot_metrics_chart(metrics_hm, 'M√©tricas de Qualidade (Heuristics Miner)'))
    metrics['heuristics_miner'] = metrics_hm
    
    kpi_temporal = _df_projects.groupby('completion_month').agg(avg_lead_time=('actual_duration_days', 'mean'), throughput=('project_id', 'count')).reset_index()
    fig, ax1 = plt.subplots(figsize=(12, 6)); ax1.plot(kpi_temporal['completion_month'], kpi_temporal['avg_lead_time'], marker='o', color='b', label='Lead Time'); ax2 = ax1.twinx(); ax2.bar(kpi_temporal['completion_month'], kpi_temporal['throughput'], color='g', alpha=0.6, label='Throughput'); fig.suptitle('S√©ries Temporais de KPIs de Performance'); fig.legend()
    plots['kpi_time_series'] = convert_fig_to_bytes(fig)
    
    fig_gantt, ax_gantt = plt.subplots(figsize=(20, max(10, len(_df_projects) * 0.4))); all_projects = _df_projects.sort_values('start_date')['project_id'].tolist(); gantt_data = _df_tasks_raw[_df_tasks_raw['project_id'].isin(all_projects)].sort_values(['project_id', 'start_date']); project_y_map = {proj_id: i for i, proj_id in enumerate(all_projects)}; color_map = {task_name: plt.get_cmap('viridis', gantt_data['task_name'].nunique())(i) for i, task_name in enumerate(gantt_data['task_name'].unique())};
    for _, task in gantt_data.iterrows(): ax_gantt.barh(project_y_map[task['project_id']], (task['end_date'] - task['start_date']).days + 1, left=task['start_date'], height=0.6, color=color_map[task['task_name']], edgecolor='black')
    ax_gantt.set_yticks(list(project_y_map.values())); ax_gantt.set_yticklabels([f"Projeto {pid}" for pid in project_y_map.keys()]); ax_gantt.invert_yaxis(); ax_gantt.xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m-%d')); plt.xticks(rotation=45); handles = [plt.Rectangle((0,0),1,1, color=color_map[label]) for label in color_map]; ax_gantt.legend(handles, color_map.keys(), title='Tipo de Tarefa', bbox_to_anchor=(1.05, 1), loc='upper left'); ax_gantt.set_title('Linha do Tempo de Todos os Projetos (Gantt Chart)'); fig_gantt.tight_layout()
    plots['gantt_chart_all_projects'] = convert_fig_to_bytes(fig_gantt)

    dfg_perf, _, _ = pm4py.discover_performance_dfg(log_full_pm4py)
    gviz_dfg = dfg_visualizer.apply(dfg_perf, log=log_full_pm4py, variant=dfg_visualizer.Variants.PERFORMANCE)
    plots['performance_heatmap'] = convert_gviz_to_bytes(gviz_dfg)
    
    fig, ax = plt.subplots(figsize=(8, 4)); log_df_full_lifecycle['weekday'] = log_df_full_lifecycle['time:timestamp'].dt.day_name(); weekday_order = ["Monday", "Tuesday", "Wednesday", "Thursday", "Friday", "Saturday", "Sunday"]; heatmap_data = log_df_full_lifecycle.groupby('weekday')['case:concept:name'].count().reindex(weekday_order).fillna(0); sns.barplot(x=heatmap_data.index, y=heatmap_data.values, ax=ax, hue=heatmap_data.index, legend=False, palette='viridis'); ax.set_title('Ocorr√™ncias de Atividades por Dia da Semana'); plt.xticks(rotation=45)
    plots['temporal_heatmap_fixed'] = convert_fig_to_bytes(fig)
    
    log_df_complete = pm4py.convert_to_dataframe(_event_log_pm4py)
    handovers = Counter((log_df_complete.iloc[i]['org:resource'], log_df_complete.iloc[i+1]['org:resource']) for i in range(len(log_df_complete)-1) if log_df_complete.iloc[i]['case:concept:name'] == log_df_complete.iloc[i+1]['case:concept:name'] and log_df_complete.iloc[i]['org:resource'] != log_df_complete.iloc[i+1]['org:resource'])
    fig_net, ax_net = plt.subplots(figsize=(10, 10)); G = nx.DiGraph();
    for (source, target), weight in handovers.items(): G.add_edge(str(source), str(target), weight=weight)
    pos = nx.spring_layout(G, k=0.9, iterations=50, seed=42); weights = [G[u][v]['weight'] for u,v in G.edges()]; nx.draw(G, pos, with_labels=True, node_color='skyblue', node_size=3000, edge_color='gray', width=[w*0.5 for w in weights], ax=ax_net, font_size=10, connectionstyle='arc3,rad=0.1'); nx.draw_networkx_edge_labels(G, pos, edge_labels=nx.get_edge_attributes(G, 'weight'), ax=ax_net); ax_net.set_title('Rede Social de Recursos (Handover Network)')
    plots['resource_network_adv'] = convert_fig_to_bytes(fig_net)
    
    if 'skill_level' in _df_resources.columns:
        perf_recursos = _df_full_context.groupby('resource_id').agg(total_hours=('hours_worked', 'sum'), total_tasks=('task_id', 'nunique')).reset_index()
        perf_recursos['avg_hours_per_task'] = perf_recursos['total_hours'] / perf_recursos['total_tasks']
        perf_recursos = perf_recursos.merge(_df_resources[['resource_id', 'skill_level', 'resource_name']], on='resource_id')
        fig, ax = plt.subplots(figsize=(8, 5)); sns.regplot(data=perf_recursos, x='skill_level', y='avg_hours_per_task', ax=ax); ax.set_title("Rela√ß√£o entre Skill e Performance")
        plots['skill_vs_performance_adv'] = convert_fig_to_bytes(fig)
        
        resource_role_counts = _df_full_context.groupby(['resource_name', 'skill_level']).size().reset_index(name='count')
        G_bipartite = nx.Graph(); resources_nodes = resource_role_counts['resource_name'].unique(); roles_nodes = resource_role_counts['skill_level'].unique(); G_bipartite.add_nodes_from(resources_nodes, bipartite=0); G_bipartite.add_nodes_from(roles_nodes, bipartite=1)
        for _, row in resource_role_counts.iterrows(): G_bipartite.add_edge(row['resource_name'], row['skill_level'], weight=row['count'])
        fig, ax = plt.subplots(figsize=(12, 10)); pos = nx.bipartite_layout(G_bipartite, resources_nodes); nx.draw(G_bipartite, pos, with_labels=True, node_color=['skyblue' if node in resources_nodes else 'lightgreen' for node in G_bipartite.nodes()], node_size=2000, ax=ax, font_size=8); edge_labels = nx.get_edge_attributes(G_bipartite, 'weight'); nx.draw_networkx_edge_labels(G_bipartite, pos, edge_labels=edge_labels, ax=ax); ax.set_title('Rede de Recursos por Fun√ß√£o')
        plots['resource_network_bipartite'] = convert_fig_to_bytes(fig)

    variants_df = log_df_full_lifecycle.groupby('case:concept:name').agg(variant=('concept:name', lambda x: tuple(x)), start_timestamp=('time:timestamp', 'min'), end_timestamp=('time:timestamp', 'max')).reset_index()
    variants_df['duration_hours'] = (variants_df['end_timestamp'] - variants_df['start_timestamp']).dt.total_seconds() / 3600
    variant_durations = variants_df.groupby('variant').agg(count=('case:concept:name', 'count'), avg_duration_hours=('duration_hours', 'mean')).reset_index().sort_values(by='count', ascending=False).head(10)
    variant_durations['variant_str'] = variant_durations['variant'].apply(lambda x: ' -> '.join([str(i) for i in x][:4]) + '...')
    fig, ax = plt.subplots(figsize=(8, 5)); sns.barplot(x='avg_duration_hours', y='variant_str', data=variant_durations.astype({'avg_duration_hours':'float'}), ax=ax, hue='variant_str', legend=False, palette='plasma'); ax.set_title('Dura√ß√£o M√©dia das 10 Variantes Mais Comuns'); fig.tight_layout()
    plots['variant_duration_plot'] = convert_fig_to_bytes(fig)

    aligned_traces = alignments_miner.apply(log_full_pm4py, net_im, im_im, fm_im)
    deviations_list = [{'fitness': trace['fitness'], 'deviations': sum(1 for move in trace['alignment'] if '>>' in move[0] or '>>' in move[1])} for trace in aligned_traces if 'fitness' in trace]
    deviations_df = pd.DataFrame(deviations_list)
    fig, ax = plt.subplots(figsize=(8, 5)); sns.scatterplot(x='fitness', y='deviations', data=deviations_df, alpha=0.6, ax=ax); ax.set_title('Diagrama de Dispers√£o (Fitness vs. Desvios)'); fig.tight_layout()
    plots['deviation_scatter_plot'] = convert_fig_to_bytes(fig)

    case_fitness_data = [{'project_id': str(trace.attributes['concept:name']), 'fitness': alignment['fitness']} for trace, alignment in zip(log_full_pm4py, aligned_traces) if 'concept:name' in trace.attributes]
    case_fitness_df = pd.DataFrame(case_fitness_data).merge(_df_projects[['project_id', 'end_date']], on='project_id')
    case_fitness_df['end_month'] = case_fitness_df['end_date'].dt.to_period('M').astype(str)
    monthly_fitness = case_fitness_df.groupby('end_month')['fitness'].mean().reset_index()
    fig, ax = plt.subplots(figsize=(10, 5)); sns.lineplot(data=monthly_fitness, x='end_month', y='fitness', marker='o', ax=ax); ax.set_title('Score de Conformidade ao Longo do Tempo'); ax.set_ylim(0, 1.05); ax.tick_params(axis='x', rotation=45); fig.tight_layout()
    plots['conformance_over_time_plot'] = convert_fig_to_bytes(fig)

    kpi_daily = _df_projects.groupby(_df_projects['end_date'].dt.date).agg(avg_cost_per_day=('cost_per_day', 'mean')).reset_index()
    kpi_daily.rename(columns={'end_date': 'completion_date'}, inplace=True)
    kpi_daily['completion_date'] = pd.to_datetime(kpi_daily['completion_date'])
    fig, ax = plt.subplots(figsize=(10, 5)); sns.lineplot(data=kpi_daily, x='completion_date', y='avg_cost_per_day', ax=ax); ax.set_title('Custo M√©dio por Dia ao Longo do Tempo'); fig.tight_layout()
    plots['cost_per_day_time_series'] = convert_fig_to_bytes(fig)

    df_projects_sorted = _df_projects.sort_values(by='end_date'); df_projects_sorted['cumulative_throughput'] = range(1, len(df_projects_sorted) + 1)
    fig, ax = plt.subplots(figsize=(10, 5)); sns.lineplot(x='end_date', y='cumulative_throughput', data=df_projects_sorted, ax=ax); ax.set_title('Gr√°fico Acumulado de Throughput'); fig.tight_layout()
    plots['cumulative_throughput_plot'] = convert_fig_to_bytes(fig)
    
    def generate_custom_variants_plot(event_log):
        variants = variants_filter.get_variants(event_log)
        top_variants = sorted(variants.items(), key=lambda item: len(item[1]), reverse=True)[:10]
        variant_sequences = {f"V{i+1} ({len(v)} casos)": [str(a) for a in k] for i, (k, v) in enumerate(top_variants)}
        fig, ax = plt.subplots(figsize=(12, 6)) 
        all_activities = sorted(list(set([act for seq in variant_sequences.values() for act in seq])))
        activity_to_y = {activity: i for i, activity in enumerate(all_activities)}
        for i, (variant_name, sequence) in enumerate(variant_sequences.items()):
            ax.plot(range(len(sequence)), [activity_to_y[activity] for activity in sequence], marker='o', linestyle='-', label=variant_name)
        ax.set_yticks(list(activity_to_y.values()))
        ax.set_yticklabels(list(activity_to_y.keys()))
        ax.set_title('Sequ√™ncia de Atividades das 10 Variantes Mais Comuns')
        ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left')
        fig.tight_layout()
        return fig
    plots['custom_variants_sequence_plot'] = convert_fig_to_bytes(generate_custom_variants_plot(log_full_pm4py))
    
    milestones = ['Analise e Design', 'Implementacao da Funcionalidade', 'Execucao de Testes', 'Deploy da Aplicacao']
    df_milestones = _df_tasks_raw[_df_tasks_raw['task_name'].isin(milestones)].copy()
    milestone_pairs = []
    for project_id, group in df_milestones.groupby('project_id'):
        sorted_tasks = group.sort_values('start_date')
        for i in range(len(sorted_tasks) - 1):
            duration = (sorted_tasks.iloc[i+1]['start_date'] - sorted_tasks.iloc[i]['end_date']).total_seconds() / 3600
            if duration >= 0: milestone_pairs.append({'transition': f"{sorted_tasks.iloc[i]['task_name']} -> {sorted_tasks.iloc[i+1]['task_name']}", 'duration_hours': duration})
    df_milestone_pairs = pd.DataFrame(milestone_pairs)
    if not df_milestone_pairs.empty:
        fig, ax = plt.subplots(figsize=(10, 6)); sns.boxplot(data=df_milestone_pairs, x='duration_hours', y='transition', ax=ax, orient='h', hue='transition', legend=False, palette='coolwarm'); ax.set_title('An√°lise de Tempo entre Marcos do Processo'); fig.tight_layout()
        plots['milestone_time_analysis_plot'] = convert_fig_to_bytes(fig)

    df_tasks_sorted = _df_tasks_raw.sort_values(['project_id', 'start_date']); df_tasks_sorted['previous_end_date'] = df_tasks_sorted.groupby('project_id')['end_date'].shift(1)
    df_tasks_sorted['waiting_time_days'] = (df_tasks_sorted['start_date'] - df_tasks_sorted['previous_end_date']).dt.total_seconds() / (24 * 3600)
    df_tasks_sorted.loc[df_tasks_sorted['waiting_time_days'] < 0, 'waiting_time_days'] = 0
    df_tasks_sorted['previous_task_name'] = df_tasks_sorted.groupby('project_id')['task_name'].shift(1)
    waiting_times_matrix = df_tasks_sorted.pivot_table(index='previous_task_name', columns='task_name', values='waiting_time_days', aggfunc='mean').fillna(0)
    fig, ax = plt.subplots(figsize=(10, 8)); sns.heatmap(waiting_times_matrix * 24, cmap='YlGnBu', annot=True, fmt='.1f', ax=ax, annot_kws={"size": 8}); ax.set_title('Matriz de Tempo de Espera entre Atividades (horas)'); fig.tight_layout()
    plots['waiting_time_matrix_plot'] = convert_fig_to_bytes(fig)
    
    resource_efficiency = _df_full_context.groupby('resource_name').agg(total_hours_worked=('hours_worked', 'sum'), total_tasks_completed=('task_name', 'count')).reset_index()
    resource_efficiency['avg_hours_per_task'] = resource_efficiency['total_hours_worked'] / resource_efficiency['total_tasks_completed']
    fig, ax = plt.subplots(figsize=(10, 6)); sns.barplot(data=resource_efficiency.sort_values(by='avg_hours_per_task'), x='avg_hours_per_task', y='resource_name', orient='h', ax=ax, hue='resource_name', legend=False, palette='magma'); ax.set_title('M√©tricas de Efici√™ncia Individual por Recurso'); fig.tight_layout()
    plots['resource_efficiency_plot'] = convert_fig_to_bytes(fig)

    df_tasks_sorted['sojourn_time_hours'] = df_tasks_sorted['waiting_time_days'] * 24
    waiting_time_by_task = df_tasks_sorted.groupby('task_name')['sojourn_time_hours'].mean().reset_index()
    fig, ax = plt.subplots(figsize=(10, 6)); sns.barplot(data=waiting_time_by_task.sort_values(by='sojourn_time_hours', ascending=False), x='sojourn_time_hours', y='task_name', ax=ax, hue='task_name', legend=False, palette='viridis'); ax.set_title('Tempo M√©dio de Espera por Atividade'); fig.tight_layout()
    plots['avg_waiting_time_by_activity_plot'] = convert_fig_to_bytes(fig)
    
    return plots, metrics


# --- P√ÅGINA DE LOGIN ---
def login_page():
    st.markdown("<h2>‚ú® Transforma√ß√£o Inteligente de Processos</h2>", unsafe_allow_html=True)
    username = st.text_input("Utilizador", placeholder="admin", value="admin")
    password = st.text_input("Senha", type="password", placeholder="admin", value="admin")
    
    # ENVOLVER O BOT√ÉO NA NOVA CLASSE CUSTOMIZADA
    st.markdown('<div class="login-button">', unsafe_allow_html=True) 
    if st.button("Entrar", use_container_width=True):
        if username == "admin" and password == "admin":
            st.session_state.authenticated = True
            st.session_state.user_name = "Admin"
            st.rerun()
        else:
            st.error("Utilizador ou senha inv√°lidos.")
    st.markdown('</div>', unsafe_allow_html=True)


# --- P√ÅGINA DE CONFIGURA√á√ïES / UPLOAD ---
def settings_page():
    st.title("‚öôÔ∏è Configura√ß√µes e Upload de Dados")
    st.markdown("---")
    st.subheader("Upload dos Ficheiros de Dados (.csv)")
    st.info("Por favor, carregue os 5 ficheiros CSV necess√°rios para a an√°lise.")
    file_names = ['projects', 'tasks', 'resources', 'resource_allocations', 'dependencies']
    
    upload_cols = st.columns(5)
    for i, name in enumerate(file_names):
        with upload_cols[i]:
            uploaded_file = st.file_uploader(f"Carregar `{name}.csv`", type="csv", key=f"upload_{name}")
            if uploaded_file:
                st.session_state.dfs[name] = pd.read_csv(uploaded_file)
                # Mantido o markdown para cor/estilo do texto p√≥s-upload, mas o CSS global deve cobrir (Problema 4)
                st.markdown(f'<p style="font-size: small; color: var(--text-color-dark-bg); font-weight: 700;">`{name}.csv` carregado.</p>', unsafe_allow_html=True)

    st.markdown("<br>", unsafe_allow_html=True)
    all_files_uploaded = all(st.session_state.dfs.get(name) is not None for name in file_names)
    
    if all_files_uploaded:
        # O toggle label j√° √© tratado no CSS global (Problema 4)
        if st.toggle("Visualizar as primeiras 5 linhas dos ficheiros", value=False):
            for name, df in st.session_state.dfs.items():
                st.markdown(f"**Ficheiro: `{name}.csv`**")
                st.dataframe(df.head())
        
        st.subheader("Execu√ß√£o da An√°lise")
        # Adicionado div para aplicar o CSS do bot√£o de an√°lise (Problema 6)
        st.markdown('<div class="iniciar-analise-button">', unsafe_allow_html=True)
        if st.button("üöÄ Iniciar An√°lise Completa", use_container_width=True):
            with st.spinner("A analisar os dados... Este processo pode demorar alguns minutos."):
                plots_pre, tables_pre, event_log, df_p, df_t, df_r, df_fc = run_pre_mining_analysis(st.session_state.dfs)
                st.session_state.plots_pre_mining = plots_pre
                st.session_state.tables_pre_mining = tables_pre
                st.session_state.event_log_for_cache = pm4py.convert_to_dataframe(event_log)
                st.session_state.dfs_for_cache = {'projects': df_p, 'tasks_raw': df_t, 'resources': df_r, 'full_context': df_fc}
                log_from_df = pm4py.convert_to_event_log(st.session_state.event_log_for_cache)
                dfs_cache = st.session_state.dfs_for_cache
                plots_post, metrics = run_post_mining_analysis(log_from_df, dfs_cache['projects'], dfs_cache['tasks_raw'], dfs_cache['resources'], dfs_cache['full_context'])
                st.session_state.plots_post_mining = plots_post
                st.session_state.metrics = metrics
            st.session_state.analysis_run = True
            st.success("‚úÖ An√°lise conclu√≠da! Navegue para o 'Dashboard Geral'.")
            st.balloons()
        st.markdown('</div>', unsafe_allow_html=True)
    else:
        st.warning("Aguardando o carregamento de todos os ficheiros CSV para poder iniciar a an√°lise.")


# --- P√ÅGINAS DO DASHBOARD ---
def dashboard_page():
    st.title("üè† Dashboard Geral")
    is_pre_mining_active = st.session_state.current_dashboard == "Pr√©-Minera√ß√£o"
    
    # L√≥gica para navega√ß√£o de Dashboard (Problema 1)
    c1, c2 = st.columns(2)
    with c1:
        # A classe 'active-button' √© aplicada condicionalmente
        st.markdown(f'<div class="{"active-button" if is_pre_mining_active else ""}">', unsafe_allow_html=True)
        if st.button("üìä An√°lise Pr√©-Minera√ß√£o", use_container_width=True, key="nav_pre_mining"):
            st.session_state.current_dashboard = "Pr√©-Minera√ß√£o"
            st.session_state.current_section = "overview" # Resetar se√ß√£o ao trocar de dashboard
            st.rerun()
        st.markdown('</div>', unsafe_allow_html=True)
    with c2:
        st.markdown(f'<div class="{"active-button" if not is_pre_mining_active else ""}">', unsafe_allow_html=True)
        if st.button("‚õèÔ∏è An√°lise P√≥s-Minera√ß√£o", use_container_width=True, key="nav_post_mining"):
            st.session_state.current_dashboard = "P√≥s-Minera√ß√£o"
            st.session_state.current_section = "discovery" # Resetar se√ß√£o ao trocar de dashboard
            st.rerun()
        st.markdown('</div>', unsafe_allow_html=True)

    st.markdown("---")
    if not st.session_state.analysis_run:
        st.warning("A an√°lise ainda n√£o foi executada. V√° √† p√°gina de 'Configura√ß√µes' para carregar os dados e iniciar.")
        return
        
    if st.session_state.current_dashboard == "Pr√©-Minera√ß√£o":
        render_pre_mining_dashboard()
    else:
        render_post_mining_dashboard()

def render_pre_mining_dashboard():
    sections = { "overview": "Vis√£o Geral", "performance": "Performance", "activities": "Atividades", "resources": "Recursos", "variants": "Variantes", "advanced": "Avan√ßado" }
    nav_cols = st.columns(len(sections))
    # L√≥gica para navega√ß√£o de Se√ß√µes (Problema 1)
    for i, (key, name) in enumerate(sections.items()):
        is_active = st.session_state.current_section == key
        with nav_cols[i]:
            # A classe 'active-button' √© aplicada condicionalmente
            st.markdown(f'<div class="{"active-button" if is_active else ""}">', unsafe_allow_html=True)
            if st.button(name, key=f"nav_pre_{key}", use_container_width=True):
                st.session_state.current_section = key
                st.rerun()
            st.markdown('</div>', unsafe_allow_html=True)
    
    st.markdown("<br>", unsafe_allow_html=True)
    plots = st.session_state.plots_pre_mining
    tables = st.session_state.tables_pre_mining

    if st.session_state.current_section == "overview":
        kpi_data = tables['kpi_data']
        kpi_cols = st.columns(4)
        kpi_cols[0].metric(label="Total de Projetos", value=kpi_data.get('Total de Projetos'))
        kpi_cols[1].metric(label="Total de Tarefas", value=kpi_data.get('Total de Tarefas'))
        kpi_cols[2].metric(label="Total de Recursos", value=kpi_data.get('Total de Recursos'))
        kpi_cols[3].metric(label="Dura√ß√£o M√©dia", value=f"{kpi_data.get('Dura√ß√£o M√©dia (dias)')} dias")
        # Layout de 2 colunas para gr√°ficos/tabelas
        c1, c2 = st.columns(2)
        with c1:
            create_card("Matriz de Performance (Custo vs Prazo)", "üéØ", chart_bytes=plots.get('performance_matrix'))
            create_card("Top 5 Projetos Mais Longos", "‚è≥", dataframe=tables.get('outlier_duration'))
        with c2:
            create_card("Distribui√ß√£o da Dura√ß√£o dos Projetos", "üìä", chart_bytes=plots.get('case_durations_boxplot'))
            create_card("Top 5 Projetos Mais Caros", "üí∞", dataframe=tables.get('outlier_cost'))
            
    elif st.session_state.current_section == "performance":
        c1, c2 = st.columns([1, 2])
        with c1:
            create_card("Estat√≠sticas de Lead Time e Throughput", "üìà", dataframe=tables.get('perf_stats'))
        with c2:
            create_card("Rela√ß√£o Lead Time vs Throughput", "üîó", chart_bytes=plots.get('lead_time_vs_throughput'))
        c3, c4, c5 = st.columns(3)
        with c3:
            create_card("Distribui√ß√£o do Lead Time", "‚è±Ô∏è", chart_bytes=plots.get('lead_time_hist'))
        with c4:
            create_card("Distribui√ß√£o do Throughput (horas)", "üöÄ", chart_bytes=plots.get('throughput_hist'))
        with c5:
            create_card("Boxplot do Throughput (horas)", "üì¶", chart_bytes=plots.get('throughput_boxplot'))
            
    elif st.session_state.current_section == "activities":
        c1, c2 = st.columns(2)
        with c1:
            create_card("Tempo M√©dio de Execu√ß√£o por Atividade", "üõ†Ô∏è", chart_bytes=plots.get('activity_service_times'))
            create_card("Top 10 Handoffs por Custo de Espera", "üí∏", chart_bytes=plots.get('top_handoffs_cost'))
        with c2:
            create_card("Atividades Mais Frequentes", "‚ö°", chart_bytes=plots.get('top_activities_plot'))
            create_card("Top 10 Handoffs por Tempo de Espera", "‚è≥", chart_bytes=plots.get('top_handoffs'))

    elif st.session_state.current_section == "resources":
        c1, c2 = st.columns(2)
        with c1:
            create_card("Top 10 Recursos por Horas Trabalhadas", "üí™", chart_bytes=plots.get('resource_workload'))
            create_card("Top 10 Handoffs entre Recursos", "üîÑ", chart_bytes=plots.get('resource_handoffs'))
        with c2:
            create_card("Recursos por M√©dia de Tarefas/Projeto", "üßë‚Äçüíª", chart_bytes=plots.get('resource_avg_events'))
            create_card("Custo por Tipo de Recurso", "üí∂", chart_bytes=plots.get('cost_by_resource_type'))
        # Garante que o cart√£o em linha √∫nica ocupe a largura total
        create_card("Heatmap de Esfor√ßo (Recurso vs Atividade)", "üó∫Ô∏è", chart_bytes=plots.get('resource_activity_matrix'))

    elif st.session_state.current_section == "variants":
        c1, c2 = st.columns(2)
        with c1:
            create_card("Frequ√™ncia das 10 Principais Variantes", "üé≠", chart_bytes=plots.get('variants_frequency'))
        with c2:
            create_card("Principais Loops de Rework", "üîÅ", dataframe=tables.get('rework_loops_table'))
            
    elif st.session_state.current_section == "advanced":
        kpi_data = tables.get('cost_of_delay_kpis', {})
        kpi_cols = st.columns(3)
        kpi_cols[0].metric(label="Custo Total em Atraso", value=kpi_data.get('Custo Total Projetos Atrasados', 'N/A'))
        kpi_cols[1].metric(label="Atraso M√©dio (dias)", value=kpi_data.get('Atraso M√©dio (dias)', 'N/A'))
        kpi_cols[2].metric(label="Custo M√©dio/Dia de Atraso", value=kpi_data.get('Custo M√©dio/Dia Atraso', 'N/A'))
        st.markdown("---")
        c1, c2 = st.columns(2)
        with c1:
            create_card("Impacto do Tamanho da Equipa no Atraso", "üë®‚Äçüë©‚Äçüëß‚Äçüë¶", chart_bytes=plots.get('delay_by_teamsize'))
            create_card("Efici√™ncia Semanal (Horas Trabalhadas)", "üóìÔ∏è", chart_bytes=plots.get('weekly_efficiency'))
            create_card("Gargalos: Tempo de Servi√ßo vs. Espera", "üö¶", chart_bytes=plots.get('service_vs_wait_stacked'))
            create_card("Evolu√ß√£o do Tempo M√©dio de Espera", "üìà", chart_bytes=plots.get('wait_time_evolution'))
            create_card("Dura√ß√£o M√©dia por Fase do Processo", "üóÇÔ∏è", chart_bytes=plots.get('cycle_time_breakdown'))
        with c2:
            create_card("Dura√ß√£o Mediana por Tamanho da Equipa", "‚è±Ô∏è", chart_bytes=plots.get('median_duration_by_teamsize'))
            create_card("Top Recursos por Tempo de Espera Gerado", "üõë", chart_bytes=plots.get('bottleneck_by_resource'))
            create_card("Espera vs. Execu√ß√£o (Dispers√£o)", "üîç", chart_bytes=plots.get('wait_vs_service_scatter'))
            create_card("Benchmark de Throughput por Equipa", "üèÜ", chart_bytes=plots.get('throughput_benchmark_by_teamsize'))

def render_post_mining_dashboard():
    sections = { "discovery": "Descoberta", "performance": "Performance", "resources": "Recursos", "conformance": "Conformidade" }
    nav_cols = st.columns(len(sections))
    # L√≥gica para navega√ß√£o de Se√ß√µes (Problema 1)
    for i, (key, name) in enumerate(sections.items()):
        is_active = st.session_state.current_section == key
        with nav_cols[i]:
            st.markdown(f'<div class="{"active-button" if is_active else ""}">', unsafe_allow_html=True)
            if st.button(name, key=f"nav_post_{key}", use_container_width=True):
                st.session_state.current_section = key
                st.rerun()
            st.markdown('</div>', unsafe_allow_html=True)

    st.markdown("<br>", unsafe_allow_html=True)
    plots = st.session_state.plots_post_mining
    
    if st.session_state.current_section == "discovery":
        c1, c2 = st.columns(2)
        with c1:
            create_card("Modelo - Inductive Miner", "üß≠", chart_bytes=plots.get('model_inductive_petrinet'))
            create_card("M√©tricas (Inductive Miner)", "üìä", chart_bytes=plots.get('metrics_inductive'))
        with c2:
            create_card("Modelo - Heuristics Miner", "üõ†Ô∏è", chart_bytes=plots.get('model_heuristic_petrinet'))
            create_card("M√©tricas (Heuristics Miner)", "üìà", chart_bytes=plots.get('metrics_heuristic'))
        create_card("Sequ√™ncia de Atividades das Variantes", "üé∂", chart_bytes=plots.get('custom_variants_sequence_plot'))
            
    elif st.session_state.current_section == "performance":
        create_card("Heatmap de Performance no Processo", "üî•", chart_bytes=plots.get('performance_heatmap'))
        c1, c2 = st.columns(2)
        with c1:
            create_card("S√©ries Temporais de KPIs (Lead Time vs Throughput)", "üìà", chart_bytes=plots.get('kpi_time_series'))
            create_card("Matriz de Tempo de Espera (horas)", "‚è≥", chart_bytes=plots.get('waiting_time_matrix_plot'))
        with c2:
            create_card("Atividades por Dia da Semana", "üóìÔ∏è", chart_bytes=plots.get('temporal_heatmap_fixed'))
            create_card("Tempo de Espera M√©dio por Atividade", "‚è±Ô∏è", chart_bytes=plots.get('avg_waiting_time_by_activity_plot'))
        if 'gantt_chart_all_projects' in plots:
             create_card("Linha do Tempo de Todos os Projetos (Gantt Chart)", "üìä", chart_bytes=plots.get('gantt_chart_all_projects'))
             
    elif st.session_state.current_section == "resources":
        c1, c2 = st.columns(2)
        with c1:
            create_card("Rede Social de Recursos (Handovers)", "üåê", chart_bytes=plots.get('resource_network_adv'))
            if 'skill_vs_performance_adv' in plots:
                create_card("Rela√ß√£o entre Skill e Performance", "üéì", chart_bytes=plots.get('skill_vs_performance_adv'))
        with c2:
            if 'resource_network_bipartite' in plots:
                create_card("Rede de Recursos por Fun√ß√£o", "üîó", chart_bytes=plots.get('resource_network_bipartite'))
            create_card("Efici√™ncia Individual por Recurso", "üéØ", chart_bytes=plots.get('resource_efficiency_plot'))
                
    elif st.session_state.current_section == "conformance":
        c1, c2 = st.columns(2)
        with c1:
            create_card("Dura√ß√£o M√©dia das Variantes Mais Comuns", "‚è≥", chart_bytes=plots.get('variant_duration_plot'))
            create_card("Score de Conformidade ao Longo do Tempo", "üìâ", chart_bytes=plots.get('conformance_over_time_plot'))
            create_card("Throughput Acumulado ao Longo do Tempo", "üöÄ", chart_bytes=plots.get('cumulative_throughput_plot'))
        with c2:
            create_card("Dispers√£o: Fitness vs. Desvios", "üéØ", chart_bytes=plots.get('deviation_scatter_plot'))
            create_card("Custo por Dia ao Longo do Tempo", "üí∏", chart_bytes=plots.get('cost_per_day_time_series'))
            if 'milestone_time_analysis_plot' in plots:
                create_card("An√°lise de Tempo entre Marcos do Processo", "üö©", chart_bytes=plots.get('milestone_time_analysis_plot'))

# --- CONTROLO PRINCIPAL DA APLICA√á√ÉO ---
def main():
    if not st.session_state.authenticated:
        st.markdown("""
        <style>
            [data-testid="stAppViewContainer"] > .main {
                display: flex; flex-direction: column; justify-content: center; align-items: center;
            }
        </style>
        """, unsafe_allow_html=True)
        login_page()
    else:
        with st.sidebar:
            st.markdown(f"### üë§ {st.session_state.get('user_name', 'Admin')}")
            st.markdown("---")
            if st.button("üè† Dashboard Geral", use_container_width=True):
                st.session_state.current_page = "Dashboard"
                st.rerun()
            if st.button("‚öôÔ∏è Configura√ß√µes", use_container_width=True):
                st.session_state.current_page = "Settings"
                st.rerun()
            st.markdown("<br><br>", unsafe_allow_html=True)
            if st.button("üö™ Sair", use_container_width=True):
                st.session_state.authenticated = False
                for key in list(st.session_state.keys()):
                    if key not in ['authenticated']: del st.session_state[key]
                st.rerun()
                
        if st.session_state.current_page == "Dashboard":
            dashboard_page()
        elif st.session_state.current_page == "Settings":
            settings_page()

if __name__ == "__main__":
    main()
